{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b912c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_no_outliers = pd.read_csv(\"C:/Users/Zainab/Downloads/swimming_data_no_outliers.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd09e11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to categorize swimmers based on their ranking\n",
    "def categorize_swimmer(ranking):\n",
    "    if ranking <= 3:\n",
    "        return 'Elite'\n",
    "    elif ranking <= 8:\n",
    "        return 'Competitive'\n",
    "    else:\n",
    "        return 'Developing'\n",
    "\n",
    "# Ensure 'Ranking_numeric' exists and drop rows with missing values\n",
    "df_no_outliers['Ranking_numeric'] = pd.to_numeric(df_no_outliers['Ranking'], errors='coerce')\n",
    "df_no_outliers = df_no_outliers.dropna(subset=['Ranking_numeric'])\n",
    "\n",
    "# Create a new column for the performance category\n",
    "df_no_outliers['Performance_Category'] = df_no_outliers['Ranking_numeric'].apply(categorize_swimmer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e7c8d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Competitive       1.00      1.00      1.00        56\n",
      "  Developing       1.00      1.00      1.00       387\n",
      "       Elite       1.00      1.00      1.00        21\n",
      "\n",
      "    accuracy                           1.00       464\n",
      "   macro avg       1.00      1.00      1.00       464\n",
      "weighted avg       1.00      1.00      1.00       464\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 56   0   0]\n",
      " [  0 387   0]\n",
      " [  0   0  21]]\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Define the features and target for classification\n",
    "features_class = ['Ranking_numeric', 'Distance', 'Sex', 'Event']\n",
    "target_class = 'Performance_Category'\n",
    "X_class = df_no_outliers[features_class]\n",
    "y_class = df_no_outliers[target_class]\n",
    "\n",
    "# Define which features are numeric and which are categorical\n",
    "numeric_features = ['Ranking_numeric', 'Distance']\n",
    "categorical_features = ['Sex', 'Event']\n",
    "\n",
    "# Create transformers for numeric and categorical data\n",
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Combine transformers into a preprocessor\n",
    "preprocessor_class = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Build the Random Forest pipeline for classification\n",
    "pipeline_rf = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor_class),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "# Split the data into training and testing sets (80/20 split)\n",
    "X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(\n",
    "    X_class, y_class, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Train the classifier\n",
    "pipeline_rf.fit(X_train_class, y_train_class)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_class = pipeline_rf.predict(X_test_class)\n",
    "\n",
    "# Evaluate the classifier's performance\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_class, y_pred_class))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_class, y_pred_class))\n",
    "print(\"Accuracy:\", accuracy_score(y_test_class, y_pred_class))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9840db53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Function to assign performance category based on time percentiles within each event.\n",
    "def assign_category(group):\n",
    "    # Compute the percentile rank of Time_seconds in each event.\n",
    "\n",
    "    group['percentile'] = group['Time_seconds'].rank(pct=True, method='min')\n",
    "    conditions = [\n",
    "        (group['percentile'] <= 0.2),                    # Fastest 20%\n",
    "        (group['percentile'] > 0.2) & (group['percentile'] <= 0.8),  # Middle 60%\n",
    "        (group['percentile'] > 0.8)                      # Slowest 20%\n",
    "    ]\n",
    "    choices = ['Elite', 'Competitive', 'Developing']\n",
    "    group['Performance_Category_New'] = np.select(conditions, choices, default='Competitive')\n",
    "    return group\n",
    "\n",
    "# Apply the function per event\n",
    "df_no_outliers = df_no_outliers.groupby('Event').apply(assign_category)\n",
    "\n",
    "# Drop the temporary 'percentile'  don't need it further:\n",
    "df_no_outliers = df_no_outliers.drop(columns=['percentile'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce984144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Competitive       0.94      0.99      0.96       273\n",
      "  Developing       0.97      0.95      0.96        87\n",
      "       Elite       1.00      0.88      0.93       104\n",
      "\n",
      "    accuracy                           0.96       464\n",
      "   macro avg       0.97      0.94      0.95       464\n",
      "weighted avg       0.96      0.96      0.96       464\n",
      "\n",
      "Modified Confusion Matrix:\n",
      "[[270   3   0]\n",
      " [  4  83   0]\n",
      " [ 13   0  91]]\n",
      "Modified Accuracy: 0.9568965517241379\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Define the features and new target for classification\n",
    "features_class = ['Ranking_numeric', 'Distance', 'Sex', 'Event']\n",
    "target_class_new = 'Performance_Category_New'\n",
    "\n",
    "# Ensure 'Ranking_numeric' exists if not\n",
    "df_no_outliers['Ranking_numeric'] = pd.to_numeric(df_no_outliers['Ranking'], errors='coerce')\n",
    "df_no_outliers = df_no_outliers.dropna(subset=['Ranking_numeric'])\n",
    "\n",
    "X_class_new = df_no_outliers[features_class]\n",
    "y_class_new = df_no_outliers[target_class_new]\n",
    "\n",
    "# Define which features are numeric and which are categorical\n",
    "numeric_features = ['Ranking_numeric', 'Distance']\n",
    "categorical_features = ['Sex', 'Event']\n",
    "\n",
    "# Create transformers\n",
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Combine transformers into a preprocessor for classification\n",
    "preprocessor_class = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Build the Random Forest pipeline for classification\n",
    "pipeline_rf_new = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor_class),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "# Split data into training and testing sets (80/20 split)\n",
    "X_train_class_new, X_test_class_new, y_train_class_new, y_test_class_new = train_test_split(\n",
    "    X_class_new, y_class_new, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Train the classifier with the new target\n",
    "pipeline_rf_new.fit(X_train_class_new, y_train_class_new)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_class_new = pipeline_rf_new.predict(X_test_class_new)\n",
    "\n",
    "\n",
    "print(\"Modified Classification Report:\")\n",
    "print(classification_report(y_test_class_new, y_pred_class_new))\n",
    "print(\"Modified Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_class_new, y_pred_class_new))\n",
    "print(\"Modified Accuracy:\", accuracy_score(y_test_class_new, y_pred_class_new))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38a66901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'classifier__class_weight': None, 'classifier__max_depth': None, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 100}\n",
      "Best CV Accuracy: 0.958419173890872\n",
      "Tuned Model Test Accuracy: 0.9568965517241379\n",
      "Tuned Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Competitive       0.94      0.99      0.96       273\n",
      "  Developing       0.97      0.95      0.96        87\n",
      "       Elite       1.00      0.88      0.93       104\n",
      "\n",
      "    accuracy                           0.96       464\n",
      "   macro avg       0.97      0.94      0.95       464\n",
      "weighted avg       0.96      0.96      0.96       464\n",
      "\n",
      "Tuned Confusion Matrix:\n",
      "[[270   3   0]\n",
      " [  4  83   0]\n",
      " [ 13   0  91]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# ensure 'Ranking_numeric' exists:\n",
    "df_no_outliers['Ranking_numeric'] = pd.to_numeric(df_no_outliers['Ranking'], errors='coerce')\n",
    "df_no_outliers = df_no_outliers.dropna(subset=['Ranking_numeric'])\n",
    "\n",
    "# Use the modified target:\n",
    "target_class_new = 'Performance_Category_New'\n",
    "features_class = ['Ranking_numeric', 'Distance', 'Sex', 'Event']\n",
    "\n",
    "X_class_new = df_no_outliers[features_class]\n",
    "y_class_new = df_no_outliers[target_class_new]\n",
    "\n",
    "# Define numeric and categorical features\n",
    "numeric_features = ['Ranking_numeric', 'Distance']\n",
    "categorical_features = ['Sex', 'Event']\n",
    "\n",
    "# Create transformers\n",
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Combine into a preprocessor\n",
    "preprocessor_class = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Build the Random Forest pipeline for classification \n",
    "pipeline_rf_new = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor_class),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Split data into training and test sets (80/20 split)\n",
    "X_train_class_new, X_test_class_new, y_train_class_new, y_test_class_new = train_test_split(\n",
    "    X_class_new, y_class_new, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Define a hyperparameter grid for tuning\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [100, 200, 300],\n",
    "    'classifier__max_depth': [None, 10, 20, 30],\n",
    "    'classifier__min_samples_split': [2, 5, 10],\n",
    "    'classifier__min_samples_leaf': [1, 2, 4],\n",
    "    'classifier__class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "# Set up the grid search with 5-fold cross-validation and use accuracy as scoring\n",
    "grid_search_rf = GridSearchCV(pipeline_rf_new, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the grid search on the training set\n",
    "grid_search_rf.fit(X_train_class_new, y_train_class_new)\n",
    "\n",
    "# Print the best hyperparameters and best cross-validated accuracy\n",
    "print(\"Best Parameters:\", grid_search_rf.best_params_)\n",
    "print(\"Best CV Accuracy:\", grid_search_rf.best_score_)\n",
    "\n",
    "\n",
    "best_model = grid_search_rf.best_estimator_\n",
    "y_pred_class_new_tuned = best_model.predict(X_test_class_new)\n",
    "\n",
    "print(\"Tuned Model Test Accuracy:\", accuracy_score(y_test_class_new, y_pred_class_new_tuned))\n",
    "print(\"Tuned Classification Report:\")\n",
    "print(classification_report(y_test_class_new, y_pred_class_new_tuned))\n",
    "print(\"Tuned Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_class_new, y_pred_class_new_tuned))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c61bc303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Swimmers by Predicted Category:\n",
      "Predicted_Category\n",
      "Competitive    [David Theile, John Monckton, Bob Bennett, Tom...\n",
      "Developing     [Cathy Ferguson, Ann Farlie, Elaine Tanner, El...\n",
      "Elite          [Igor Polyansky, David Berkoff, David Berkoff,...\n",
      "Name: Name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_no_outliers['Predicted_Category'] = best_model.predict(df_no_outliers[features_class])\n",
    "\n",
    "# Now, group the dataframe by the predicted category and list the swimmer names in each group.\n",
    "grouped_names = df_no_outliers.groupby('Predicted_Category')['Name'].apply(list)\n",
    "\n",
    "print(\"Swimmers by Predicted Category:\")\n",
    "print(grouped_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00b37e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved to: C:\\Users\\Zainab\\Downloads\\classified_swimming_data.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "downloads_path = os.path.join(os.path.expanduser(\"~\"), \"Downloads\", \"classified_swimming_data.csv\")\n",
    "\n",
    "\n",
    "df_no_outliers.to_csv(downloads_path, index=False)\n",
    "print(\"File saved to:\", downloads_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1ab975a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_no_outliers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5868\\1450970425.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# First, sort the DataFrame by Ranking_numeric in ascending order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mdf_sorted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_no_outliers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Ranking_numeric'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Then, group by the performance category and take the top 3 swimmers for each group\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_no_outliers' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# First, sort the DataFrame by Ranking_numeric in ascending order\n",
    "df_sorted = df_no_outliers.sort_values(by='Ranking_numeric', ascending=True)\n",
    "\n",
    "# Then, group by the performance category and take the top 3 swimmers for each group\n",
    "top3_per_category = df_sorted.groupby('Performance_Category_New').head(3)\n",
    "\n",
    "\n",
    "print(top3_per_category[['Name', 'Ranking_numeric', 'Time_seconds', 'Performance_Category_New']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e37f0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
